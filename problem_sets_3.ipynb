{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making Difficulty-Calibrated Datasets for Different LLM's"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import transformers\n",
    "import torch\n",
    "import dotenv\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import string\n",
    "from tqdm import tqdm\n",
    "import pysat\n",
    "\n",
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dot_product_problem_set(vec_len, vec_mag, num_problems, avoid_collisions=True):\n",
    "    if vec_len < 2:\n",
    "        raise ValueError(\"Need vectors of length 2 or greater to have two intermediates\")\n",
    "    if vec_mag < 2:\n",
    "        raise ValueError(\"We remove 0 and 1 from the vector magnitudes to avoid collisions\")\n",
    "    if avoid_collisions and not ((vec_mag-1)**vec_len > num_problems):\n",
    "        raise ValueError(\"To avoid collisions, need a bigger space than the number of problems requested\")\n",
    "\n",
    "    def make_dot_product_problem(vec_len, avoid_collisions=True):\n",
    "        a = np.random.randint(2, vec_mag, vec_len)\n",
    "        b = np.random.randint(2, vec_mag, vec_len)\n",
    "        problem = (f\"[{', '.join([str(x) for x in a])}] ⋅ [{', '.join([str(x) for x in b])}]\"\n",
    "        , np.dot(a, b)\n",
    "        , a[0]*b[0],\n",
    "        a[-1]*b[-1])\n",
    "        if avoid_collisions and str(problem[2]) in problem[0] or str(problem[3]) in problem[0]:\n",
    "            return make_dot_product_problem(vec_len, avoid_collisions)\n",
    "        return problem\n",
    "\n",
    "    return pd.DataFrame(\n",
    "        [make_dot_product_problem(vec_len, avoid_collisions) for _ in range(num_problems)],\n",
    "        columns=['problem', 'correct_solution', 'intermediate_1', 'intermediate_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_problem_cot(pipeline, problem, sys_prompt, cot_prompt):\n",
    "    terminators = [\n",
    "        pipeline.tokenizer.eos_token_id,\n",
    "        pipeline.tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
    "    ]\n",
    "    \n",
    "    if 'gemma' not in str(pipeline.__dict__).lower():\n",
    "        messages = [\n",
    "        {\"role\": \"system\", \"content\": sys_prompt + ' ' + cot_prompt},\n",
    "        {\"role\": \"user\", \"content\": problem},\n",
    "        ]\n",
    "    else:\n",
    "        messages = [{\"role\": \"user\", \"content\": sys_prompt + ' ' + cot_prompt + '\\n' + problem}]\n",
    "\n",
    "    outputs = pipeline(\n",
    "    messages,\n",
    "    max_new_tokens=256,\n",
    "    eos_token_id=terminators,\n",
    "    do_sample=True,\n",
    "    temperature=0.6,\n",
    "    top_p=0.9,\n",
    "    pad_token_id=pipeline.tokenizer.eos_token_id\n",
    "    )\n",
    "\n",
    "    return outputs[0]['generated_text'][-1]['content']\n",
    "\n",
    "def solve_problem_memo(pipeline, problem, sys_prompt, memo_prompt, max_toks=10): # setting max_toks to 1 because we're doing small digit numbers\n",
    "    terminators = [\n",
    "        pipeline.tokenizer.eos_token_id,\n",
    "        pipeline.tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
    "    ]\n",
    "    \n",
    "    if 'gemma' not in str(pipeline.__dict__).lower():\n",
    "        messages = [\n",
    "        {\"role\": \"system\", \"content\": sys_prompt + ' ' + memo_prompt},\n",
    "        {\"role\": \"user\", \"content\": problem},\n",
    "        ]\n",
    "    else:\n",
    "        messages = [{\"role\": \"user\", \"content\": sys_prompt + ' ' + memo_prompt + '\\n' + problem}]\n",
    "\n",
    "    outputs = pipeline(\n",
    "    messages,\n",
    "    max_new_tokens=max_toks,\n",
    "    eos_token_id=terminators,\n",
    "    do_sample=True,\n",
    "    temperature=0.6,\n",
    "    top_p=0.9,\n",
    "    pad_token_id=pipeline.tokenizer.eos_token_id\n",
    "    )\n",
    "\n",
    "    return outputs[0]['generated_text'][-1]['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem_prompt = \"What is the dot product of these two vectors?\"\n",
    "cot_prompt = \"Show your work.\"\n",
    "memo_prompt = \"\"\"Answer with only a number. Do not do any calculations. For example:\n",
    "                 Problem: [2, 9, -3] ⋅ [-6, -2, -9]\n",
    "                 Solution: -3\n",
    "                 \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def repeated_solve_problem_memo(pipeline, problem, sys_prompt, memo_prompt, max_toks=10, return_retries=False):\n",
    "    soln = solve_problem_memo(pipeline, problem, sys_prompt, memo_prompt, max_toks=max_toks).strip()\n",
    "    i = 0\n",
    "    while (soln[0]== '-' and len(soln) > 4) or (soln[0]!= '-' and len(soln) > 3):\n",
    "        if i >= 50: # tap out\n",
    "            return soln if not return_retries else (soln, i)\n",
    "        i += 1\n",
    "        print('retrying', i, soln, list(soln))\n",
    "        soln = solve_problem_memo(pipeline, problem, sys_prompt, memo_prompt, max_toks=max_toks).strip()\n",
    "    return soln if not return_retries else (soln, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_memo_prompt(pipeline, memo_prompt, problems, n):\n",
    "    dot_problems = problems\n",
    "    memo_solutions = []\n",
    "    memo_correct = 0\n",
    "    max_retries = 0\n",
    "    for i, row in tqdm(list(dot_problems.iterrows())[:n]):\n",
    "        sol, retries = repeated_solve_problem_memo(pipeline, row['problem'], problem_prompt, memo_prompt=memo_prompt, max_toks=20, return_retries=True)\n",
    "        memo_solutions.append(sol)\n",
    "        memo_correct += str(row['correct_solution']) in memo_solutions[-1]\n",
    "        max_retries = max(max_retries, retries)\n",
    "    print(f\"Max retries: {max_retries}\")\n",
    "    print(f\"Correct memorization: {memo_correct}/{n}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dot_test(pipeline, dot_problems, n, problem_prompt=problem_prompt, cot_prompt=cot_prompt, memo_prompt=memo_prompt):\n",
    "    cot_solutions = []\n",
    "    cot_correct = 0\n",
    "    for i, row in tqdm(list(dot_problems.iterrows())[:n]):\n",
    "        cot_solutions.append(solve_problem_cot(pipeline, row['problem'], problem_prompt, cot_prompt))\n",
    "        cot_correct += str(row['correct_solution']) in cot_solutions[-1]\n",
    "\n",
    "    memo_solutions = []\n",
    "    memo_correct = 0\n",
    "    for i, row in tqdm(list(dot_problems.iterrows())[:n]):\n",
    "        memo_solutions.append(solve_problem_memo(pipeline, row['problem'], problem_prompt, memo_prompt))\n",
    "        memo_correct += str(row['correct_solution']) in memo_solutions[-1]\n",
    "\n",
    "    print(f\"Correct COT: {cot_correct}/{n}\")\n",
    "    print(f\"Correct memorization: {memo_correct}/{n}\")\n",
    "    return cot_solutions, memo_solutions, dot_problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "problems = make_dot_product_problem_set(4, 10, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "n=100\n",
    "n70b=10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Llama 8b reproduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:04<00:00,  1.07s/it]\n"
     ]
    }
   ],
   "source": [
    "llama8b_pipe = transformers.pipeline(\n",
    "        \"text-generation\",\n",
    "        model=\"meta-llama/Meta-Llama-3-8B-Instruct\",\n",
    "        model_kwargs={\"torch_dtype\": torch.bfloat16},\n",
    "        device_map=\"auto\",\n",
    "        token=os.getenv('HF_TOKEN')\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  9.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max retries: 0/10\n",
      "Correct memorization: 0/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:03<00:00,  6.32s/it]\n",
      "100%|██████████| 10/10 [00:00<00:00, 11.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct COT: 10/10\n",
      "Correct memorization: 0/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_memo_prompt(llama8b_pipe, memo_prompt=memo_prompt, problems=problems, n=n)\n",
    "results[('llama8b', 4, 10)] = dot_test(llama8b_pipe, dot_problems=problems, n=n, problem_prompt=problem_prompt, cot_prompt=cot_prompt, memo_prompt=memo_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Llama 70B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 30/30 [00:33<00:00,  1.13s/it]\n",
      "Some parameters are on the meta device device because they were offloaded to the cpu.\n"
     ]
    }
   ],
   "source": [
    "llama70b_pipe = transformers.pipeline(\n",
    "        \"text-generation\",\n",
    "        model=\"meta-llama/Meta-Llama-3-70B-Instruct\",\n",
    "        model_kwargs={\"torch_dtype\": torch.bfloat16},\n",
    "        device_map=\"auto\",\n",
    "        token=os.getenv('HF_TOKEN')\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:25<00:00,  2.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max retries: 0/10\n",
      "Correct memorization: 0/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_memo_prompt(llama70b_pipe, memo_prompt=memo_prompt, problems=problems, n=n70b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [34:41<00:00, 208.10s/it]\n",
      "100%|██████████| 10/10 [00:25<00:00,  2.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct COT: 10/10\n",
      "Correct memorization: 0/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results[('llama70b', 4, 10)] = dot_test(llama70b_pipe, problems, n=n70b, problem_prompt=problem_prompt, cot_prompt=cot_prompt, memo_prompt=memo_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phi 3 mini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  2.37it/s]\n",
      "Some parameters are on the meta device device because they were offloaded to the cpu.\n"
     ]
    }
   ],
   "source": [
    "phi3_pipe = transformers.pipeline(\n",
    "        \"text-generation\",\n",
    "        model=\"microsoft/Phi-3-mini-4k-instruct\",\n",
    "        model_kwargs={\"torch_dtype\": torch.bfloat16},\n",
    "        device_map=\"auto\",\n",
    "        token=os.getenv('HF_TOKEN')\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 14/100 [00:39<04:02,  2.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrying 1 To find the dot product of two vectors, you multiply their corresponding components and then sum those products. ['T', 'o', ' ', 'f', 'i', 'n', 'd', ' ', 't', 'h', 'e', ' ', 'd', 'o', 't', ' ', 'p', 'r', 'o', 'd', 'u', 'c', 't', ' ', 'o', 'f', ' ', 't', 'w', 'o', ' ', 'v', 'e', 'c', 't', 'o', 'r', 's', ',', ' ', 'y', 'o', 'u', ' ', 'm', 'u', 'l', 't', 'i', 'p', 'l', 'y', ' ', 't', 'h', 'e', 'i', 'r', ' ', 'c', 'o', 'r', 'r', 'e', 's', 'p', 'o', 'n', 'd', 'i', 'n', 'g', ' ', 'c', 'o', 'm', 'p', 'o', 'n', 'e', 'n', 't', 's', ' ', 'a', 'n', 'd', ' ', 't', 'h', 'e', 'n', ' ', 's', 'u', 'm', ' ', 't', 'h', 'o', 's', 'e', ' ', 'p', 'r', 'o', 'd', 'u', 'c', 't', 's', '.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 32/100 [01:40<02:54,  2.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrying 1 The dot product of the vectors [5, 4, 4, 6] and [ ['T', 'h', 'e', ' ', 'd', 'o', 't', ' ', 'p', 'r', 'o', 'd', 'u', 'c', 't', ' ', 'o', 'f', ' ', 't', 'h', 'e', ' ', 'v', 'e', 'c', 't', 'o', 'r', 's', ' ', '[', '5', ',', ' ', '4', ',', ' ', '4', ',', ' ', '6', ']', ' ', 'a', 'n', 'd', ' ', '[']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 43/100 [02:21<02:38,  2.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrying 1 The dot product of [5, 2, 8, 3] and [2, ['T', 'h', 'e', ' ', 'd', 'o', 't', ' ', 'p', 'r', 'o', 'd', 'u', 'c', 't', ' ', 'o', 'f', ' ', '[', '5', ',', ' ', '2', ',', ' ', '8', ',', ' ', '3', ']', ' ', 'a', 'n', 'd', ' ', '[', '2', ',']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 56/100 [03:09<02:03,  2.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrying 1 To find the dot product of two vectors, you multiply each corresponding pair of elements and then sum those ['T', 'o', ' ', 'f', 'i', 'n', 'd', ' ', 't', 'h', 'e', ' ', 'd', 'o', 't', ' ', 'p', 'r', 'o', 'd', 'u', 'c', 't', ' ', 'o', 'f', ' ', 't', 'w', 'o', ' ', 'v', 'e', 'c', 't', 'o', 'r', 's', ',', ' ', 'y', 'o', 'u', ' ', 'm', 'u', 'l', 't', 'i', 'p', 'l', 'y', ' ', 'e', 'a', 'c', 'h', ' ', 'c', 'o', 'r', 'r', 'e', 's', 'p', 'o', 'n', 'd', 'i', 'n', 'g', ' ', 'p', 'a', 'i', 'r', ' ', 'o', 'f', ' ', 'e', 'l', 'e', 'm', 'e', 'n', 't', 's', ' ', 'a', 'n', 'd', ' ', 't', 'h', 'e', 'n', ' ', 's', 'u', 'm', ' ', 't', 'h', 'o', 's', 'e']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 61/100 [03:33<02:18,  3.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrying 1 The dot product of these two vectors is 180. ['T', 'h', 'e', ' ', 'd', 'o', 't', ' ', 'p', 'r', 'o', 'd', 'u', 'c', 't', ' ', 'o', 'f', ' ', 't', 'h', 'e', 's', 'e', ' ', 't', 'w', 'o', ' ', 'v', 'e', 'c', 't', 'o', 'r', 's', ' ', 'i', 's', ' ', '1', '8', '0', '.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 71/100 [04:07<01:18,  2.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrying 1 9*5 + 9*7 + 9*2 + 4*3 = ['9', '*', '5', ' ', '+', ' ', '9', '*', '7', ' ', '+', ' ', '9', '*', '2', ' ', '+', ' ', '4', '*', '3', ' ', '=']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 75/100 [04:29<01:38,  3.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrying 1 The dot product of these two vectors is 100. ['T', 'h', 'e', ' ', 'd', 'o', 't', ' ', 'p', 'r', 'o', 'd', 'u', 'c', 't', ' ', 'o', 'f', ' ', 't', 'h', 'e', 's', 'e', ' ', 't', 'w', 'o', ' ', 'v', 'e', 'c', 't', 'o', 'r', 's', ' ', 'i', 's', ' ', '1', '0', '0', '.']\n",
      "retrying 2 The dot product of the two vectors is 2*6 + 7*8 + 9 ['T', 'h', 'e', ' ', 'd', 'o', 't', ' ', 'p', 'r', 'o', 'd', 'u', 'c', 't', ' ', 'o', 'f', ' ', 't', 'h', 'e', ' ', 't', 'w', 'o', ' ', 'v', 'e', 'c', 't', 'o', 'r', 's', ' ', 'i', 's', ' ', '2', '*', '6', ' ', '+', ' ', '7', '*', '8', ' ', '+', ' ', '9']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 81/100 [05:05<01:14,  3.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrying 1 To find the dot product of two vectors, you multiply corresponding elements and sum the results. For the ['T', 'o', ' ', 'f', 'i', 'n', 'd', ' ', 't', 'h', 'e', ' ', 'd', 'o', 't', ' ', 'p', 'r', 'o', 'd', 'u', 'c', 't', ' ', 'o', 'f', ' ', 't', 'w', 'o', ' ', 'v', 'e', 'c', 't', 'o', 'r', 's', ',', ' ', 'y', 'o', 'u', ' ', 'm', 'u', 'l', 't', 'i', 'p', 'l', 'y', ' ', 'c', 'o', 'r', 'r', 'e', 's', 'p', 'o', 'n', 'd', 'i', 'n', 'g', ' ', 'e', 'l', 'e', 'm', 'e', 'n', 't', 's', ' ', 'a', 'n', 'd', ' ', 's', 'u', 'm', ' ', 't', 'h', 'e', ' ', 'r', 'e', 's', 'u', 'l', 't', 's', '.', ' ', 'F', 'o', 'r', ' ', 't', 'h', 'e']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 82/100 [05:18<02:02,  6.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrying 1 To find the dot product of two vectors, you multiply the corresponding elements of the vectors and then sum ['T', 'o', ' ', 'f', 'i', 'n', 'd', ' ', 't', 'h', 'e', ' ', 'd', 'o', 't', ' ', 'p', 'r', 'o', 'd', 'u', 'c', 't', ' ', 'o', 'f', ' ', 't', 'w', 'o', ' ', 'v', 'e', 'c', 't', 'o', 'r', 's', ',', ' ', 'y', 'o', 'u', ' ', 'm', 'u', 'l', 't', 'i', 'p', 'l', 'y', ' ', 't', 'h', 'e', ' ', 'c', 'o', 'r', 'r', 'e', 's', 'p', 'o', 'n', 'd', 'i', 'n', 'g', ' ', 'e', 'l', 'e', 'm', 'e', 'n', 't', 's', ' ', 'o', 'f', ' ', 't', 'h', 'e', ' ', 'v', 'e', 'c', 't', 'o', 'r', 's', ' ', 'a', 'n', 'd', ' ', 't', 'h', 'e', 'n', ' ', 's', 'u', 'm']\n",
      "retrying 2 To find the dot product of two vectors without doing any calculations, we can use the properties of dot ['T', 'o', ' ', 'f', 'i', 'n', 'd', ' ', 't', 'h', 'e', ' ', 'd', 'o', 't', ' ', 'p', 'r', 'o', 'd', 'u', 'c', 't', ' ', 'o', 'f', ' ', 't', 'w', 'o', ' ', 'v', 'e', 'c', 't', 'o', 'r', 's', ' ', 'w', 'i', 't', 'h', 'o', 'u', 't', ' ', 'd', 'o', 'i', 'n', 'g', ' ', 'a', 'n', 'y', ' ', 'c', 'a', 'l', 'c', 'u', 'l', 'a', 't', 'i', 'o', 'n', 's', ',', ' ', 'w', 'e', ' ', 'c', 'a', 'n', ' ', 'u', 's', 'e', ' ', 't', 'h', 'e', ' ', 'p', 'r', 'o', 'p', 'e', 'r', 't', 'i', 'e', 's', ' ', 'o', 'f', ' ', 'd', 'o', 't']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 97/100 [06:20<00:08,  2.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrying 1 To find the dot product of two vectors without performing any calculations, we can apply the properties of the ['T', 'o', ' ', 'f', 'i', 'n', 'd', ' ', 't', 'h', 'e', ' ', 'd', 'o', 't', ' ', 'p', 'r', 'o', 'd', 'u', 'c', 't', ' ', 'o', 'f', ' ', 't', 'w', 'o', ' ', 'v', 'e', 'c', 't', 'o', 'r', 's', ' ', 'w', 'i', 't', 'h', 'o', 'u', 't', ' ', 'p', 'e', 'r', 'f', 'o', 'r', 'm', 'i', 'n', 'g', ' ', 'a', 'n', 'y', ' ', 'c', 'a', 'l', 'c', 'u', 'l', 'a', 't', 'i', 'o', 'n', 's', ',', ' ', 'w', 'e', ' ', 'c', 'a', 'n', ' ', 'a', 'p', 'p', 'l', 'y', ' ', 't', 'h', 'e', ' ', 'p', 'r', 'o', 'p', 'e', 'r', 't', 'i', 'e', 's', ' ', 'o', 'f', ' ', 't', 'h', 'e']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [06:39<00:00,  4.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max retries: 2\n",
      "Correct memorization: 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_memo_prompt(phi3_pipe, memo_prompt=memo_prompt, problems=problems, n=n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [2:23:22<00:00, 86.02s/it] \n",
      "100%|██████████| 100/100 [05:30<00:00,  3.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct COT: 94/100\n",
      "Correct memorization: 0/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results[('phi3', 4, 10)] = dot_test(phi3_pipe, dot_problems=problems, n=n, problem_prompt=problem_prompt, cot_prompt=cot_prompt, memo_prompt=memo_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:04<00:00,  1.14s/it]\n"
     ]
    }
   ],
   "source": [
    "gemma2_pipe = transformers.pipeline(\n",
    "        \"text-generation\",\n",
    "        model=\"google/gemma-2-9b-it\",\n",
    "        model_kwargs={\"torch_dtype\": torch.bfloat16},\n",
    "        device_map=\"auto\",\n",
    "        token=os.getenv('HF_TOKEN')\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [17:33<00:00, 10.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max retries: 0\n",
      "Correct memorization: 2/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_memo_prompt(gemma2_pipe, memo_prompt=memo_prompt, problems=problems, n=n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 10/100 [02:54<25:57, 17.31s/it]You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "100%|██████████| 100/100 [28:53<00:00, 17.33s/it]\n",
      "100%|██████████| 100/100 [00:55<00:00,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct COT: 93/100\n",
      "Correct memorization: 2/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results[('gemma2', 4, 10)] = dot_test(gemma2_pipe, dot_problems=problems, n=n, problem_prompt=problem_prompt, cot_prompt=cot_prompt, memo_prompt=memo_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
