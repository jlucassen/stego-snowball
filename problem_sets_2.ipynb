{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import transformers\n",
    "import torch\n",
    "import dotenv\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import string\n",
    "from tqdm import tqdm\n",
    "\n",
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:03<00:00,  1.31it/s]\n"
     ]
    }
   ],
   "source": [
    "model_id = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "\n",
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model_id,\n",
    "    model_kwargs={\"torch_dtype\": torch.bfloat16},\n",
    "    device_map=\"auto\",\n",
    "    token=os.getenv('HF_TOKEN')\n",
    ")\n",
    "\n",
    "terminators = [\n",
    "    pipeline.tokenizer.eos_token_id,\n",
    "    pipeline.tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rule 110 Cellular Automaton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_cellular_problem_set(size, steps, num_problems, boundary='wrap'):\n",
    "    if steps < 3:\n",
    "        raise ValueError(\"Need 3 steps to have a solution and 2 intermediates\")\n",
    "    def int_to_binary_list(n, min_length=8):\n",
    "        binary = bin(n)[2:]  # Convert to binary string and remove '0b' prefix\n",
    "        binary_list = [int(b) for b in binary.zfill(min_length)]  # Pad with zeros if necessary\n",
    "        return binary_list\n",
    "    \n",
    "    dict_110 = {\n",
    "        (0, 0, 0): 0,\n",
    "        (0, 0, 1): 1,\n",
    "        (0, 1, 0): 1,\n",
    "        (0, 1, 1): 1,\n",
    "        (1, 0, 0): 0,\n",
    "        (1, 0, 1): 1,\n",
    "        (1, 1, 0): 1,\n",
    "        (1, 1, 1): 0\n",
    "    }\n",
    "\n",
    "    def rule_110(prev):\n",
    "        next_state = []\n",
    "        for i in range(len(prev)):\n",
    "            left = prev[(i-1) % len(prev)] if boundary == 'wrap' or (i > 0 and i < len(prev)-1) else boundary\n",
    "            center = prev[i]\n",
    "            right = prev[(i+1) % len(prev)] if boundary == 'wrap' or (i > 0 and i < len(prev)-1) else boundary\n",
    "            pattern = (left, center, right)\n",
    "            next_state.append(dict_110[pattern])\n",
    "        return next_state\n",
    "    \n",
    "    def make_rule_110_problem(initial_state, steps):\n",
    "        current_state = initial_state\n",
    "        states = [current_state]\n",
    "        for _ in range(steps):\n",
    "            current_state = rule_110(current_state)\n",
    "            states.append(current_state)\n",
    "        return (''.join(str(x) for x in initial_state),\n",
    "            ''.join(str(x) for x in states[-1]),\n",
    "            ''.join(str(x) for x in states[1]),\n",
    "            ''.join(str(x) for x in states[-2]))\n",
    "\n",
    "    return pd.DataFrame(\n",
    "        [make_rule_110_problem(int_to_binary_list(((i+1)*33581)%(2**(size))), steps) for i in range(num_problems)]\n",
    "        , columns=['problem', 'correct_solution', 'intermediate_1', 'intermediate_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>problem</th>\n",
       "      <th>correct_solution</th>\n",
       "      <th>intermediate_1</th>\n",
       "      <th>intermediate_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1100101101</td>\n",
       "      <td>1001000011</td>\n",
       "      <td>1101111111</td>\n",
       "      <td>1111000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1001011010</td>\n",
       "      <td>1010000110</td>\n",
       "      <td>1011111110</td>\n",
       "      <td>1110000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>110000111</td>\n",
       "      <td>110110001</td>\n",
       "      <td>110001101</td>\n",
       "      <td>110011111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10110100</td>\n",
       "      <td>10001100</td>\n",
       "      <td>11111100</td>\n",
       "      <td>10000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1111100001</td>\n",
       "      <td>1011101101</td>\n",
       "      <td>1000100011</td>\n",
       "      <td>1001100111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>1100010100</td>\n",
       "      <td>1111101100</td>\n",
       "      <td>1100111100</td>\n",
       "      <td>1101100100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>1001000001</td>\n",
       "      <td>1001001101</td>\n",
       "      <td>1011000011</td>\n",
       "      <td>1111000111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>101101110</td>\n",
       "      <td>100011010</td>\n",
       "      <td>111111010</td>\n",
       "      <td>100001110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>10011011</td>\n",
       "      <td>10100011</td>\n",
       "      <td>10111111</td>\n",
       "      <td>11100001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>1111001000</td>\n",
       "      <td>1110001000</td>\n",
       "      <td>1001011000</td>\n",
       "      <td>1011111000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        problem correct_solution intermediate_1 intermediate_2\n",
       "0    1100101101       1001000011     1101111111     1111000001\n",
       "1    1001011010       1010000110     1011111110     1110000010\n",
       "2     110000111        110110001      110001101      110011111\n",
       "3      10110100         10001100       11111100       10000100\n",
       "4    1111100001       1011101101     1000100011     1001100111\n",
       "..          ...              ...            ...            ...\n",
       "995  1100010100       1111101100     1100111100     1101100100\n",
       "996  1001000001       1001001101     1011000011     1111000111\n",
       "997   101101110        100011010      111111010      100001110\n",
       "998    10011011         10100011       10111111       11100001\n",
       "999  1111001000       1110001000     1001011000     1011111000\n",
       "\n",
       "[1000 rows x 4 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_cellular_problem_set(10, 3, 1000, boundary=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pysat.formula import CNF\n",
    "from pysat.solvers import Glucose3\n",
    "\n",
    "def solve_nsat(clauses):\n",
    "    # Create a CNF formula\n",
    "    cnf = CNF()\n",
    "    for clause in clauses:\n",
    "        cnf.append(clause)\n",
    "\n",
    "    # Create a SAT solver\n",
    "    with Glucose3(bootstrap_with=cnf) as solver:\n",
    "        # Check if the formula is satisfiable\n",
    "        if solver.solve():\n",
    "            return solver.get_model()\n",
    "        else:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_nsat_problem_set(vars_per_clause, num_clauses, num_problems):\n",
    "    def make_nsat_problem(vars_per_clause, num_clauses):\n",
    "        text_variables = [string.ascii_lowercase[i] for i in range(vars_per_clause)]\n",
    "        text_problem = []\n",
    "        pysat_problem = []\n",
    "        for _ in range(num_clauses):\n",
    "            clause = random.sample(range(vars_per_clause), 3)\n",
    "            signs = [random.choice([-1, 1]) for _ in range(3)]\n",
    "            pysat_clause = [signs[i]*(var+1) for i, var in enumerate(clause)]\n",
    "            pysat_problem.append(pysat_clause)\n",
    "            pysat_solution = solve_nsat(pysat_problem)\n",
    "            if pysat_solution is None:\n",
    "                text_solution = None\n",
    "            else:\n",
    "                text_solution_letters = [f\"{'¬' if var <0 else ''}{text_variables[abs(var)-1]}\" for i, var in enumerate(pysat_solution)]\n",
    "                text_solution = f\"{' ^ '.join(text_solution_letters)}\"\n",
    "\n",
    "            text_clause = [f\"{'¬' if signs[i] == -1 else ''}{text_variables[var]}\" for i, var in enumerate(clause)]\n",
    "            text_problem.append(f\"({' v '.join(text_clause)})\")\n",
    "        return ' ^ '.join(text_problem), text_solution, None, None\n",
    "\n",
    "    return pd.DataFrame(\n",
    "        [make_nsat_problem(vars_per_clause, num_clauses) for _ in range(num_problems)],\n",
    "        columns=['problem', 'correct_solution', 'intermediate_1', 'intermediate_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>problem</th>\n",
       "      <th>correct_solution</th>\n",
       "      <th>intermediate_1</th>\n",
       "      <th>intermediate_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(¬b v c v a) ^ (b v ¬a v ¬c) ^ (c v b v ¬a) ^ ...</td>\n",
       "      <td>¬a ^ b ^ c</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(c v ¬b v a) ^ (a v ¬c v ¬b) ^ (¬c v b v a) ^ ...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(c v ¬a v b) ^ (a v ¬b v c) ^ (c v ¬b v ¬a) ^ ...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(b v ¬a v c) ^ (c v ¬a v ¬b) ^ (c v b v ¬a) ^ ...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(¬a v b v ¬c) ^ (¬a v ¬c v ¬b) ^ (a v ¬c v b) ...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>(¬a v c v b) ^ (a v c v ¬b) ^ (a v ¬b v c) ^ (...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>(c v ¬a v b) ^ (¬c v ¬a v ¬b) ^ (c v ¬b v ¬a) ...</td>\n",
       "      <td>¬a ^ b ^ c</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>(a v c v ¬b) ^ (c v ¬b v ¬a) ^ (¬b v a v ¬c) ^...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>(a v c v ¬b) ^ (¬c v ¬a v b) ^ (c v b v a) ^ (...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>(¬c v b v ¬a) ^ (a v ¬b v c) ^ (b v c v ¬a) ^ ...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               problem correct_solution  \\\n",
       "0    (¬b v c v a) ^ (b v ¬a v ¬c) ^ (c v b v ¬a) ^ ...       ¬a ^ b ^ c   \n",
       "1    (c v ¬b v a) ^ (a v ¬c v ¬b) ^ (¬c v b v a) ^ ...             None   \n",
       "2    (c v ¬a v b) ^ (a v ¬b v c) ^ (c v ¬b v ¬a) ^ ...             None   \n",
       "3    (b v ¬a v c) ^ (c v ¬a v ¬b) ^ (c v b v ¬a) ^ ...             None   \n",
       "4    (¬a v b v ¬c) ^ (¬a v ¬c v ¬b) ^ (a v ¬c v b) ...             None   \n",
       "..                                                 ...              ...   \n",
       "995  (¬a v c v b) ^ (a v c v ¬b) ^ (a v ¬b v c) ^ (...             None   \n",
       "996  (c v ¬a v b) ^ (¬c v ¬a v ¬b) ^ (c v ¬b v ¬a) ...       ¬a ^ b ^ c   \n",
       "997  (a v c v ¬b) ^ (c v ¬b v ¬a) ^ (¬b v a v ¬c) ^...             None   \n",
       "998  (a v c v ¬b) ^ (¬c v ¬a v b) ^ (c v b v a) ^ (...             None   \n",
       "999  (¬c v b v ¬a) ^ (a v ¬b v c) ^ (b v c v ¬a) ^ ...             None   \n",
       "\n",
       "    intermediate_1 intermediate_2  \n",
       "0             None           None  \n",
       "1             None           None  \n",
       "2             None           None  \n",
       "3             None           None  \n",
       "4             None           None  \n",
       "..             ...            ...  \n",
       "995           None           None  \n",
       "996           None           None  \n",
       "997           None           None  \n",
       "998           None           None  \n",
       "999           None           None  \n",
       "\n",
       "[1000 rows x 4 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_nsat_problem_set(3, 20, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dot Product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dot_product_problem_set(vec_len, vec_mag, num_problems):\n",
    "    if vec_len < 2:\n",
    "        raise ValueError(\"Need vectors of length 2 or greater to have two intermediates\")\n",
    "    def make_dot_product_problem(vec_len):\n",
    "        a = np.random.randint(-vec_mag, vec_mag, vec_len)\n",
    "        b = np.random.randint(-vec_mag, vec_mag, vec_len)\n",
    "        return (f\"[{', '.join([str(x) for x in a])}] ⋅ [{', '.join([str(x) for x in b])}]\"\n",
    "        , np.dot(a, b)\n",
    "        , a[0]*b[0],\n",
    "        a[-1]*b[-1])\n",
    "\n",
    "    return pd.DataFrame(\n",
    "        [make_dot_product_problem(vec_len) for _ in range(num_problems)],\n",
    "        columns=['problem', 'correct_solution', 'intermediate_1', 'intermediate_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>problem</th>\n",
       "      <th>correct_solution</th>\n",
       "      <th>intermediate_1</th>\n",
       "      <th>intermediate_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0, 7, 5] ⋅ [1, -2, -9]</td>\n",
       "      <td>-59</td>\n",
       "      <td>0</td>\n",
       "      <td>-45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-3, -8, -7] ⋅ [9, -10, -3]</td>\n",
       "      <td>74</td>\n",
       "      <td>-27</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[-3, -3, -9] ⋅ [-6, 8, -9]</td>\n",
       "      <td>75</td>\n",
       "      <td>18</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[8, -6, 6] ⋅ [-9, -7, -2]</td>\n",
       "      <td>-42</td>\n",
       "      <td>-72</td>\n",
       "      <td>-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[-1, -1, 0] ⋅ [-6, 5, 1]</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>[-5, -5, -2] ⋅ [3, 8, -1]</td>\n",
       "      <td>-53</td>\n",
       "      <td>-15</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>[7, -10, 7] ⋅ [-7, 8, 2]</td>\n",
       "      <td>-115</td>\n",
       "      <td>-49</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>[-4, -1, -6] ⋅ [2, -6, -3]</td>\n",
       "      <td>16</td>\n",
       "      <td>-8</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>[-4, 8, 1] ⋅ [-1, 2, 4]</td>\n",
       "      <td>24</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>[-7, 3, 0] ⋅ [-10, -5, -8]</td>\n",
       "      <td>55</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         problem  correct_solution  intermediate_1  \\\n",
       "0        [0, 7, 5] ⋅ [1, -2, -9]               -59               0   \n",
       "1    [-3, -8, -7] ⋅ [9, -10, -3]                74             -27   \n",
       "2     [-3, -3, -9] ⋅ [-6, 8, -9]                75              18   \n",
       "3      [8, -6, 6] ⋅ [-9, -7, -2]               -42             -72   \n",
       "4       [-1, -1, 0] ⋅ [-6, 5, 1]                 1               6   \n",
       "..                           ...               ...             ...   \n",
       "995    [-5, -5, -2] ⋅ [3, 8, -1]               -53             -15   \n",
       "996     [7, -10, 7] ⋅ [-7, 8, 2]              -115             -49   \n",
       "997   [-4, -1, -6] ⋅ [2, -6, -3]                16              -8   \n",
       "998      [-4, 8, 1] ⋅ [-1, 2, 4]                24               4   \n",
       "999   [-7, 3, 0] ⋅ [-10, -5, -8]                55              70   \n",
       "\n",
       "     intermediate_2  \n",
       "0               -45  \n",
       "1                21  \n",
       "2                81  \n",
       "3               -12  \n",
       "4                 0  \n",
       "..              ...  \n",
       "995               2  \n",
       "996              14  \n",
       "997              18  \n",
       "998               4  \n",
       "999               0  \n",
       "\n",
       "[1000 rows x 4 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_dot_product_problem_set(3, 10, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_problem_cot(problem, sys_prompt, cot_prompt):\n",
    "    messages = [\n",
    "    {\"role\": \"system\", \"content\": sys_prompt + ' ' + cot_prompt},\n",
    "    {\"role\": \"user\", \"content\": problem},\n",
    "    ]\n",
    "\n",
    "    outputs = pipeline(\n",
    "    messages,\n",
    "    max_new_tokens=256,\n",
    "    eos_token_id=terminators,\n",
    "    do_sample=True,\n",
    "    temperature=0.6,\n",
    "    top_p=0.9,\n",
    "    pad_token_id=pipeline.tokenizer.eos_token_id\n",
    "    )\n",
    "\n",
    "    return outputs[0]['generated_text'][-1]['content']\n",
    "\n",
    "def solve_problem_memo(problem, sys_prompt, memo_prompt, max_toks=10): # setting max_toks to 1 because we're doing small digit numbers\n",
    "    messages = [\n",
    "    {\"role\": \"system\", \"content\": sys_prompt + ' ' + memo_prompt},\n",
    "    {\"role\": \"user\", \"content\": problem},\n",
    "    ]\n",
    "    print(messages)\n",
    "\n",
    "    outputs = pipeline(\n",
    "    messages,\n",
    "    max_new_tokens=max_toks,\n",
    "    eos_token_id=terminators,\n",
    "    do_sample=True,\n",
    "    temperature=0.6,\n",
    "    top_p=0.9,\n",
    "    pad_token_id=pipeline.tokenizer.eos_token_id\n",
    "    )\n",
    "\n",
    "    return outputs[0]['generated_text'][-1]['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem_prompt = \"What is the dot product of these two vectors?\"\n",
    "cot_prompt = \"Show your work.\"\n",
    "memo_prompt = \"Answer with only a number.\"\n",
    "n=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dot_test(dot_problems, problem_prompt=problem_prompt, cot_prompt=cot_prompt, memo_prompt=memo_prompt, n=n):\n",
    "    cot_solutions = []\n",
    "    cot_correct = 0\n",
    "    for i, row in tqdm(list(dot_problems.iterrows())[:n]):\n",
    "        cot_solutions.append(solve_problem_cot(row['problem'], problem_prompt, cot_prompt))\n",
    "        cot_correct += str(row['correct_solution']) in cot_solutions[-1]\n",
    "\n",
    "    memo_solutions = []\n",
    "    memo_correct = 0\n",
    "    for i, row in tqdm(list(dot_problems.iterrows())[:n]):\n",
    "        memo_solutions.append(solve_problem_memo(row['problem'], problem_prompt, memo_prompt))\n",
    "        memo_correct += str(row['correct_solution']) in memo_solutions[-1]\n",
    "\n",
    "    print(cot_correct, memo_correct)\n",
    "    return cot_solutions, memo_solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [05:20<00:00,  3.20s/it]\n",
      "100%|██████████| 100/100 [00:17<00:00,  5.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results[(3, 10)] = dot_test(make_dot_product_problem_set(3, 10, n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [04:18<00:00,  2.59s/it]\n",
      "100%|██████████| 100/100 [00:13<00:00,  7.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results[(2, 10)] = dot_test(make_dot_product_problem_set(2, 10, n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [04:13<00:00,  2.53s/it]\n",
      "100%|██████████| 100/100 [00:12<00:00,  8.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results[(2, 20)] = dot_test(make_dot_product_problem_set(2, 20, n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [07:20<00:00,  4.41s/it]\n",
      "100%|██████████| 100/100 [00:16<00:00,  6.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results[(5, 10)] = dot_test(make_dot_product_problem_set(5, 10, n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 2/100 [00:00<00:08, 11.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'role': 'system', 'content': 'What is the dot product of these two vectors? Answer with only a number. Do not do any calculations.'}, {'role': 'user', 'content': '[-1, -9, 6] ⋅ [-3, -5, -1]'}]\n",
      "[{'role': 'system', 'content': 'What is the dot product of these two vectors? Answer with only a number. Do not do any calculations.'}, {'role': 'user', 'content': '[-5, -4, -3] ⋅ [6, 7, -6]'}]\n",
      "[{'role': 'system', 'content': 'What is the dot product of these two vectors? Answer with only a number. Do not do any calculations.'}, {'role': 'user', 'content': '[-3, 6, 1] ⋅ [-2, 0, 5]'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 4/100 [00:00<00:07, 13.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'role': 'system', 'content': 'What is the dot product of these two vectors? Answer with only a number. Do not do any calculations.'}, {'role': 'user', 'content': '[-6, -1, -1] ⋅ [-8, 1, 0]'}]\n",
      "[{'role': 'system', 'content': 'What is the dot product of these two vectors? Answer with only a number. Do not do any calculations.'}, {'role': 'user', 'content': '[1, -7, 0] ⋅ [-3, -3, 0]'}]\n",
      "[{'role': 'system', 'content': 'What is the dot product of these two vectors? Answer with only a number. Do not do any calculations.'}, {'role': 'user', 'content': '[8, -8, -10] ⋅ [-5, 4, -2]'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 8/100 [00:00<00:08, 11.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'role': 'system', 'content': 'What is the dot product of these two vectors? Answer with only a number. Do not do any calculations.'}, {'role': 'user', 'content': '[5, -9, 7] ⋅ [-8, 6, -8]'}]\n",
      "[{'role': 'system', 'content': 'What is the dot product of these two vectors? Answer with only a number. Do not do any calculations.'}, {'role': 'user', 'content': '[0, 4, 2] ⋅ [-10, -9, -2]'}]\n",
      "[{'role': 'system', 'content': 'What is the dot product of these two vectors? Answer with only a number. Do not do any calculations.'}, {'role': 'user', 'content': '[7, -9, 5] ⋅ [-5, -9, -6]'}]\n",
      "[{'role': 'system', 'content': 'What is the dot product of these two vectors? Answer with only a number. Do not do any calculations.'}, {'role': 'user', 'content': '[-4, 8, 6] ⋅ [1, 7, 9]'}]\n",
      "retrying 1 -4*1 + 8*7 + 6*9 = 68\n",
      "[{'role': 'system', 'content': 'What is the dot product of these two vectors? Answer with only a number. Do not do any calculations.'}, {'role': 'user', 'content': '[-4, 8, 6] ⋅ [1, 7, 9]'}]\n",
      "retrying 2 -4 + 56 + 54 = 106\n",
      "[{'role': 'system', 'content': 'What is the dot product of these two vectors? Answer with only a number. Do not do any calculations.'}, {'role': 'user', 'content': '[-4, 8, 6] ⋅ [1, 7, 9]'}]\n",
      "retrying 3 -4 + 56 + 54 = 106\n",
      "[{'role': 'system', 'content': 'What is the dot product of these two vectors? Answer with only a number. Do not do any calculations.'}, {'role': 'user', 'content': '[-4, 8, 6] ⋅ [1, 7, 9]'}]\n",
      "retrying 4 -4*1 + 8*7 + 6*9 = 62\n",
      "[{'role': 'system', 'content': 'What is the dot product of these two vectors? Answer with only a number. Do not do any calculations.'}, {'role': 'user', 'content': '[-4, 8, 6] ⋅ [1, 7, 9]'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 9/100 [00:03<00:31,  2.92it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/root/stego-snowball/problem_sets_2.ipynb Cell 21\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bdatacrunch/root/stego-snowball/problem_sets_2.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39msum\u001b[39m([\u001b[39mlen\u001b[39m([n \u001b[39mfor\u001b[39;00m n \u001b[39min\u001b[39;00m x \u001b[39mif\u001b[39;00m n\u001b[39m.\u001b[39misnumeric()]) \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m2\u001b[39m \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m memo_solutions]))\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bdatacrunch/root/stego-snowball/problem_sets_2.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(memo_solutions))\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bdatacrunch/root/stego-snowball/problem_sets_2.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=19'>20</a>\u001b[0m test_memo_prompt(\u001b[39m\"\u001b[39;49m\u001b[39mAnswer with only a number. Do not do any calculations.\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "\u001b[1;32m/root/stego-snowball/problem_sets_2.ipynb Cell 21\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bdatacrunch/root/stego-snowball/problem_sets_2.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m memo_correct \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bdatacrunch/root/stego-snowball/problem_sets_2.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39mfor\u001b[39;00m i, row \u001b[39min\u001b[39;00m tqdm(\u001b[39mlist\u001b[39m(dot_problems\u001b[39m.\u001b[39miterrows())[:n]):\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bdatacrunch/root/stego-snowball/problem_sets_2.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m     memo_solutions\u001b[39m.\u001b[39mappend(repeated_solve_problem_memo(row[\u001b[39m'\u001b[39;49m\u001b[39mproblem\u001b[39;49m\u001b[39m'\u001b[39;49m], problem_prompt, memo_prompt\u001b[39m=\u001b[39;49mmemo_prompt, max_toks\u001b[39m=\u001b[39;49m\u001b[39m20\u001b[39;49m))\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bdatacrunch/root/stego-snowball/problem_sets_2.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m     memo_correct \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(row[\u001b[39m'\u001b[39m\u001b[39mcorrect_solution\u001b[39m\u001b[39m'\u001b[39m]) \u001b[39min\u001b[39;00m memo_solutions[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bdatacrunch/root/stego-snowball/problem_sets_2.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39msum\u001b[39m([\u001b[39mlen\u001b[39m([n \u001b[39mfor\u001b[39;00m n \u001b[39min\u001b[39;00m x \u001b[39mif\u001b[39;00m n\u001b[39m.\u001b[39misnumeric()]) \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m2\u001b[39m \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m memo_solutions]))\n",
      "\u001b[1;32m/root/stego-snowball/problem_sets_2.ipynb Cell 21\u001b[0m line \u001b[0;36m7\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bdatacrunch/root/stego-snowball/problem_sets_2.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m     i \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bdatacrunch/root/stego-snowball/problem_sets_2.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mretrying\u001b[39m\u001b[39m'\u001b[39m, i, soln)\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bdatacrunch/root/stego-snowball/problem_sets_2.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m     soln \u001b[39m=\u001b[39m solve_problem_memo(problem, sys_prompt, memo_prompt, max_toks\u001b[39m=\u001b[39;49mmax_toks)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bdatacrunch/root/stego-snowball/problem_sets_2.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mreturn\u001b[39;00m soln\n",
      "\u001b[1;32m/root/stego-snowball/problem_sets_2.ipynb Cell 21\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bdatacrunch/root/stego-snowball/problem_sets_2.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=19'>20</a>\u001b[0m messages \u001b[39m=\u001b[39m [\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bdatacrunch/root/stego-snowball/problem_sets_2.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=20'>21</a>\u001b[0m {\u001b[39m\"\u001b[39m\u001b[39mrole\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39msystem\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcontent\u001b[39m\u001b[39m\"\u001b[39m: sys_prompt \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m memo_prompt},\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bdatacrunch/root/stego-snowball/problem_sets_2.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=21'>22</a>\u001b[0m {\u001b[39m\"\u001b[39m\u001b[39mrole\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39muser\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcontent\u001b[39m\u001b[39m\"\u001b[39m: problem},\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bdatacrunch/root/stego-snowball/problem_sets_2.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=22'>23</a>\u001b[0m ]\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bdatacrunch/root/stego-snowball/problem_sets_2.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39mprint\u001b[39m(messages)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bdatacrunch/root/stego-snowball/problem_sets_2.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=25'>26</a>\u001b[0m outputs \u001b[39m=\u001b[39m pipeline(\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bdatacrunch/root/stego-snowball/problem_sets_2.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=26'>27</a>\u001b[0m messages,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bdatacrunch/root/stego-snowball/problem_sets_2.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=27'>28</a>\u001b[0m max_new_tokens\u001b[39m=\u001b[39;49mmax_toks,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bdatacrunch/root/stego-snowball/problem_sets_2.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=28'>29</a>\u001b[0m eos_token_id\u001b[39m=\u001b[39;49mterminators,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bdatacrunch/root/stego-snowball/problem_sets_2.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=29'>30</a>\u001b[0m do_sample\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bdatacrunch/root/stego-snowball/problem_sets_2.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=30'>31</a>\u001b[0m temperature\u001b[39m=\u001b[39;49m\u001b[39m0.6\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bdatacrunch/root/stego-snowball/problem_sets_2.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=31'>32</a>\u001b[0m top_p\u001b[39m=\u001b[39;49m\u001b[39m0.9\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bdatacrunch/root/stego-snowball/problem_sets_2.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=32'>33</a>\u001b[0m pad_token_id\u001b[39m=\u001b[39;49mpipeline\u001b[39m.\u001b[39;49mtokenizer\u001b[39m.\u001b[39;49meos_token_id\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bdatacrunch/root/stego-snowball/problem_sets_2.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=33'>34</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bdatacrunch/root/stego-snowball/problem_sets_2.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=35'>36</a>\u001b[0m \u001b[39mreturn\u001b[39;00m outputs[\u001b[39m0\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mgenerated_text\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mcontent\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/text_generation.py:257\u001b[0m, in \u001b[0;36mTextGenerationPipeline.__call__\u001b[0;34m(self, text_inputs, **kwargs)\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\n\u001b[1;32m    253\u001b[0m     text_inputs, (\u001b[39mlist\u001b[39m, \u001b[39mtuple\u001b[39m, KeyDataset) \u001b[39mif\u001b[39;00m is_torch_available() \u001b[39melse\u001b[39;00m (\u001b[39mlist\u001b[39m, \u001b[39mtuple\u001b[39m)\n\u001b[1;32m    254\u001b[0m ) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(text_inputs[\u001b[39m0\u001b[39m], (\u001b[39mlist\u001b[39m, \u001b[39mtuple\u001b[39m, \u001b[39mdict\u001b[39m)):\n\u001b[1;32m    255\u001b[0m     \u001b[39m# We have one or more prompts in list-of-dicts format, so this is chat mode\u001b[39;00m\n\u001b[1;32m    256\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(text_inputs[\u001b[39m0\u001b[39m], \u001b[39mdict\u001b[39m):\n\u001b[0;32m--> 257\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(Chat(text_inputs), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    258\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    259\u001b[0m         chats \u001b[39m=\u001b[39m [Chat(chat) \u001b[39mfor\u001b[39;00m chat \u001b[39min\u001b[39;00m text_inputs]  \u001b[39m# 🐈 🐈 🐈\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1254\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[0;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1246\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mnext\u001b[39m(\n\u001b[1;32m   1247\u001b[0m         \u001b[39miter\u001b[39m(\n\u001b[1;32m   1248\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_iterator(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1251\u001b[0m         )\n\u001b[1;32m   1252\u001b[0m     )\n\u001b[1;32m   1253\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1254\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun_single(inputs, preprocess_params, forward_params, postprocess_params)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1261\u001b[0m, in \u001b[0;36mPipeline.run_single\u001b[0;34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001b[0m\n\u001b[1;32m   1259\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun_single\u001b[39m(\u001b[39mself\u001b[39m, inputs, preprocess_params, forward_params, postprocess_params):\n\u001b[1;32m   1260\u001b[0m     model_inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpreprocess(inputs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpreprocess_params)\n\u001b[0;32m-> 1261\u001b[0m     model_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(model_inputs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mforward_params)\n\u001b[1;32m   1262\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpostprocess(model_outputs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpostprocess_params)\n\u001b[1;32m   1263\u001b[0m     \u001b[39mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1161\u001b[0m, in \u001b[0;36mPipeline.forward\u001b[0;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[1;32m   1159\u001b[0m     \u001b[39mwith\u001b[39;00m inference_context():\n\u001b[1;32m   1160\u001b[0m         model_inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ensure_tensor_on_device(model_inputs, device\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[0;32m-> 1161\u001b[0m         model_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_forward(model_inputs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mforward_params)\n\u001b[1;32m   1162\u001b[0m         model_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ensure_tensor_on_device(model_outputs, device\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mdevice(\u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[1;32m   1163\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/text_generation.py:351\u001b[0m, in \u001b[0;36mTextGenerationPipeline._forward\u001b[0;34m(self, model_inputs, **generate_kwargs)\u001b[0m\n\u001b[1;32m    348\u001b[0m         generate_kwargs[\u001b[39m\"\u001b[39m\u001b[39mmin_length\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m prefix_length\n\u001b[1;32m    350\u001b[0m \u001b[39m# BS x SL\u001b[39;00m\n\u001b[0;32m--> 351\u001b[0m generated_sequence \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mgenerate(input_ids\u001b[39m=\u001b[39;49minput_ids, attention_mask\u001b[39m=\u001b[39;49mattention_mask, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mgenerate_kwargs)\n\u001b[1;32m    352\u001b[0m out_b \u001b[39m=\u001b[39m generated_sequence\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n\u001b[1;32m    353\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mframework \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[39mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1989\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1981\u001b[0m     input_ids, model_kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   1982\u001b[0m         input_ids\u001b[39m=\u001b[39minput_ids,\n\u001b[1;32m   1983\u001b[0m         expand_size\u001b[39m=\u001b[39mgeneration_config\u001b[39m.\u001b[39mnum_return_sequences,\n\u001b[1;32m   1984\u001b[0m         is_encoder_decoder\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   1985\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   1986\u001b[0m     )\n\u001b[1;32m   1988\u001b[0m     \u001b[39m# 13. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[0;32m-> 1989\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sample(\n\u001b[1;32m   1990\u001b[0m         input_ids,\n\u001b[1;32m   1991\u001b[0m         logits_processor\u001b[39m=\u001b[39;49mprepared_logits_processor,\n\u001b[1;32m   1992\u001b[0m         logits_warper\u001b[39m=\u001b[39;49mprepared_logits_warper,\n\u001b[1;32m   1993\u001b[0m         stopping_criteria\u001b[39m=\u001b[39;49mprepared_stopping_criteria,\n\u001b[1;32m   1994\u001b[0m         generation_config\u001b[39m=\u001b[39;49mgeneration_config,\n\u001b[1;32m   1995\u001b[0m         synced_gpus\u001b[39m=\u001b[39;49msynced_gpus,\n\u001b[1;32m   1996\u001b[0m         streamer\u001b[39m=\u001b[39;49mstreamer,\n\u001b[1;32m   1997\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_kwargs,\n\u001b[1;32m   1998\u001b[0m     )\n\u001b[1;32m   2000\u001b[0m \u001b[39melif\u001b[39;00m generation_mode \u001b[39min\u001b[39;00m (GenerationMode\u001b[39m.\u001b[39mBEAM_SAMPLE, GenerationMode\u001b[39m.\u001b[39mBEAM_SEARCH):\n\u001b[1;32m   2001\u001b[0m     \u001b[39m# 11. prepare logits warper\u001b[39;00m\n\u001b[1;32m   2002\u001b[0m     prepared_logits_warper \u001b[39m=\u001b[39m (\n\u001b[1;32m   2003\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_logits_warper(generation_config, device\u001b[39m=\u001b[39minput_ids\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m   2004\u001b[0m         \u001b[39mif\u001b[39;00m generation_config\u001b[39m.\u001b[39mdo_sample\n\u001b[1;32m   2005\u001b[0m         \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   2006\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:2932\u001b[0m, in \u001b[0;36mGenerationMixin._sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, logits_warper, **model_kwargs)\u001b[0m\n\u001b[1;32m   2929\u001b[0m model_inputs\u001b[39m.\u001b[39mupdate({\u001b[39m\"\u001b[39m\u001b[39moutput_hidden_states\u001b[39m\u001b[39m\"\u001b[39m: output_hidden_states} \u001b[39mif\u001b[39;00m output_hidden_states \u001b[39melse\u001b[39;00m {})\n\u001b[1;32m   2931\u001b[0m \u001b[39m# forward pass to get next token\u001b[39;00m\n\u001b[0;32m-> 2932\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_inputs, return_dict\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m   2934\u001b[0m \u001b[39mif\u001b[39;00m synced_gpus \u001b[39mand\u001b[39;00m this_peer_finished:\n\u001b[1;32m   2935\u001b[0m     \u001b[39mcontinue\u001b[39;00m  \u001b[39m# don't waste resources running the code we don't need\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1564\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/llama/modeling_llama.py:1141\u001b[0m, in \u001b[0;36mLlamaForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m   1138\u001b[0m return_dict \u001b[39m=\u001b[39m return_dict \u001b[39mif\u001b[39;00m return_dict \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39muse_return_dict\n\u001b[1;32m   1140\u001b[0m \u001b[39m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m-> 1141\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(\n\u001b[1;32m   1142\u001b[0m     input_ids\u001b[39m=\u001b[39;49minput_ids,\n\u001b[1;32m   1143\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m   1144\u001b[0m     position_ids\u001b[39m=\u001b[39;49mposition_ids,\n\u001b[1;32m   1145\u001b[0m     past_key_values\u001b[39m=\u001b[39;49mpast_key_values,\n\u001b[1;32m   1146\u001b[0m     inputs_embeds\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[1;32m   1147\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m   1148\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   1149\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m   1150\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m   1151\u001b[0m     cache_position\u001b[39m=\u001b[39;49mcache_position,\n\u001b[1;32m   1152\u001b[0m )\n\u001b[1;32m   1154\u001b[0m hidden_states \u001b[39m=\u001b[39m outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m   1155\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mpretraining_tp \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1564\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/llama/modeling_llama.py:944\u001b[0m, in \u001b[0;36mLlamaModel.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m    932\u001b[0m     layer_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    933\u001b[0m         decoder_layer\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m,\n\u001b[1;32m    934\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    941\u001b[0m         position_embeddings,\n\u001b[1;32m    942\u001b[0m     )\n\u001b[1;32m    943\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 944\u001b[0m     layer_outputs \u001b[39m=\u001b[39m decoder_layer(\n\u001b[1;32m    945\u001b[0m         hidden_states,\n\u001b[1;32m    946\u001b[0m         attention_mask\u001b[39m=\u001b[39;49mcausal_mask,\n\u001b[1;32m    947\u001b[0m         position_ids\u001b[39m=\u001b[39;49mposition_ids,\n\u001b[1;32m    948\u001b[0m         past_key_value\u001b[39m=\u001b[39;49mpast_key_values,\n\u001b[1;32m    949\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    950\u001b[0m         use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m    951\u001b[0m         cache_position\u001b[39m=\u001b[39;49mcache_position,\n\u001b[1;32m    952\u001b[0m         position_embeddings\u001b[39m=\u001b[39;49mposition_embeddings,\n\u001b[1;32m    953\u001b[0m     )\n\u001b[1;32m    955\u001b[0m hidden_states \u001b[39m=\u001b[39m layer_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    957\u001b[0m \u001b[39mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1564\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/llama/modeling_llama.py:677\u001b[0m, in \u001b[0;36mLlamaDecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, position_embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    674\u001b[0m hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_layernorm(hidden_states)\n\u001b[1;32m    676\u001b[0m \u001b[39m# Self Attention\u001b[39;00m\n\u001b[0;32m--> 677\u001b[0m hidden_states, self_attn_weights, present_key_value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mself_attn(\n\u001b[1;32m    678\u001b[0m     hidden_states\u001b[39m=\u001b[39;49mhidden_states,\n\u001b[1;32m    679\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m    680\u001b[0m     position_ids\u001b[39m=\u001b[39;49mposition_ids,\n\u001b[1;32m    681\u001b[0m     past_key_value\u001b[39m=\u001b[39;49mpast_key_value,\n\u001b[1;32m    682\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    683\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m    684\u001b[0m     cache_position\u001b[39m=\u001b[39;49mcache_position,\n\u001b[1;32m    685\u001b[0m     position_embeddings\u001b[39m=\u001b[39;49mposition_embeddings,\n\u001b[1;32m    686\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    687\u001b[0m )\n\u001b[1;32m    688\u001b[0m hidden_states \u001b[39m=\u001b[39m residual \u001b[39m+\u001b[39m hidden_states\n\u001b[1;32m    690\u001b[0m \u001b[39m# Fully Connected\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1564\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/llama/modeling_llama.py:578\u001b[0m, in \u001b[0;36mLlamaSdpaAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, position_embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    576\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    577\u001b[0m     cos, sin \u001b[39m=\u001b[39m position_embeddings\n\u001b[0;32m--> 578\u001b[0m query_states, key_states \u001b[39m=\u001b[39m apply_rotary_pos_emb(query_states, key_states, cos, sin)\n\u001b[1;32m    580\u001b[0m \u001b[39mif\u001b[39;00m past_key_value \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    581\u001b[0m     \u001b[39m# sin and cos are specific to RoPE models; cache_position needed for the static cache\u001b[39;00m\n\u001b[1;32m    582\u001b[0m     cache_kwargs \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39msin\u001b[39m\u001b[39m\"\u001b[39m: sin, \u001b[39m\"\u001b[39m\u001b[39mcos\u001b[39m\u001b[39m\"\u001b[39m: cos, \u001b[39m\"\u001b[39m\u001b[39mcache_position\u001b[39m\u001b[39m\"\u001b[39m: cache_position}\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/llama/modeling_llama.py:219\u001b[0m, in \u001b[0;36mapply_rotary_pos_emb\u001b[0;34m(q, k, cos, sin, position_ids, unsqueeze_dim)\u001b[0m\n\u001b[1;32m    217\u001b[0m cos \u001b[39m=\u001b[39m cos\u001b[39m.\u001b[39munsqueeze(unsqueeze_dim)\n\u001b[1;32m    218\u001b[0m sin \u001b[39m=\u001b[39m sin\u001b[39m.\u001b[39munsqueeze(unsqueeze_dim)\n\u001b[0;32m--> 219\u001b[0m q_embed \u001b[39m=\u001b[39m (q \u001b[39m*\u001b[39m cos) \u001b[39m+\u001b[39m (rotate_half(q) \u001b[39m*\u001b[39m sin)\n\u001b[1;32m    220\u001b[0m k_embed \u001b[39m=\u001b[39m (k \u001b[39m*\u001b[39m cos) \u001b[39m+\u001b[39m (rotate_half(k) \u001b[39m*\u001b[39m sin)\n\u001b[1;32m    221\u001b[0m \u001b[39mreturn\u001b[39;00m q_embed, k_embed\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/llama/modeling_llama.py:194\u001b[0m, in \u001b[0;36mrotate_half\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    192\u001b[0m x1 \u001b[39m=\u001b[39m x[\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m, : x\u001b[39m.\u001b[39mshape[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m \u001b[39m2\u001b[39m]\n\u001b[1;32m    193\u001b[0m x2 \u001b[39m=\u001b[39m x[\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m, x\u001b[39m.\u001b[39mshape[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m \u001b[39m2\u001b[39m :]\n\u001b[0;32m--> 194\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mcat((\u001b[39m-\u001b[39;49mx2, x1), dim\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def repeated_solve_problem_memo(problem, sys_prompt, memo_prompt, max_toks=10):\n",
    "    soln = solve_problem_memo(problem, sys_prompt, memo_prompt, max_toks=max_toks)\n",
    "    i = 0\n",
    "    while sum([len([n for n in soln if n.isnumeric()]) > 3]):\n",
    "        i += 1\n",
    "        print('retrying', i, soln)\n",
    "        soln = solve_problem_memo(problem, sys_prompt, memo_prompt, max_toks=max_toks)\n",
    "    return soln\n",
    "\n",
    "def test_memo_prompt(memo_prompt):\n",
    "    dot_problems = make_dot_product_problem_set(3, 10, n)\n",
    "    memo_solutions = []\n",
    "    memo_correct = 0\n",
    "    for i, row in tqdm(list(dot_problems.iterrows())[:n]):\n",
    "        memo_solutions.append(repeated_solve_problem_memo(row['problem'], problem_prompt, memo_prompt=memo_prompt, max_toks=20))\n",
    "        memo_correct += str(row['correct_solution']) in memo_solutions[-1]\n",
    "    print(sum([len([n for n in x if n.isnumeric()]) <= 2 for x in memo_solutions]))\n",
    "    print('\\n'.join(memo_solutions))\n",
    "\n",
    "test_memo_prompt(\"Answer with only a number. Do not do any calculations.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "censored-cognition",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
