{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making Difficulty-Calibrated Datasets for Different LLM's"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import transformers\n",
    "import torch\n",
    "import dotenv\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import string\n",
    "from tqdm import tqdm\n",
    "import pysat\n",
    "\n",
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dot_product_problem_set(vec_len, vec_mag, num_problems, avoid_collisions=True):\n",
    "    if vec_len < 2:\n",
    "        raise ValueError(\"Need vectors of length 2 or greater to have two intermediates\")\n",
    "    if vec_mag < 2:\n",
    "        raise ValueError(\"We remove 0 and 1 from the vector magnitudes to avoid collisions\")\n",
    "    if avoid_collisions and not ((vec_mag-1)**vec_len > num_problems):\n",
    "        raise ValueError(\"To avoid collisions, need a bigger space than the number of problems requested\")\n",
    "\n",
    "    def make_dot_product_problem(vec_len, avoid_collisions=True):\n",
    "        a = np.random.randint(2, vec_mag, vec_len)\n",
    "        b = np.random.randint(2, vec_mag, vec_len)\n",
    "        problem = (f\"[{', '.join([str(x) for x in a])}] ⋅ [{', '.join([str(x) for x in b])}]\"\n",
    "        , np.dot(a, b)\n",
    "        , a[0]*b[0],\n",
    "        a[-1]*b[-1])\n",
    "        if avoid_collisions and str(problem[2]) in problem[0] or str(problem[3]) in problem[0]:\n",
    "            print(f\"resampling {problem}\")\n",
    "            return make_dot_product_problem(vec_len, avoid_collisions)\n",
    "        return problem\n",
    "\n",
    "    return pd.DataFrame(\n",
    "        [make_dot_product_problem(vec_len, avoid_collisions) for _ in range(num_problems)],\n",
    "        columns=['problem', 'correct_solution', 'intermediate_1', 'intermediate_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_problem_cot(model_id, problem, sys_prompt, cot_prompt):\n",
    "    pipeline = transformers.pipeline(\n",
    "        \"text-generation\",\n",
    "        model=model_id,\n",
    "        model_kwargs={\"torch_dtype\": torch.bfloat16},\n",
    "        device_map=\"auto\",\n",
    "        token=os.getenv('HF_TOKEN')\n",
    "    )\n",
    "\n",
    "    terminators = [\n",
    "        pipeline.tokenizer.eos_token_id,\n",
    "        pipeline.tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
    "    ]\n",
    "    \n",
    "    messages = [\n",
    "    {\"role\": \"system\", \"content\": sys_prompt + ' ' + cot_prompt},\n",
    "    {\"role\": \"user\", \"content\": problem},\n",
    "    ]\n",
    "\n",
    "    outputs = pipeline(\n",
    "    messages,\n",
    "    max_new_tokens=256,\n",
    "    eos_token_id=terminators,\n",
    "    do_sample=True,\n",
    "    temperature=0.6,\n",
    "    top_p=0.9,\n",
    "    pad_token_id=pipeline.tokenizer.eos_token_id\n",
    "    )\n",
    "\n",
    "    return outputs[0]['generated_text'][-1]['content']\n",
    "\n",
    "def solve_problem_memo(model_id, problem, sys_prompt, memo_prompt, max_toks=10): # setting max_toks to 1 because we're doing small digit numbers\n",
    "    pipeline = transformers.pipeline(\n",
    "        \"text-generation\",\n",
    "        model=model_id,\n",
    "        model_kwargs={\"torch_dtype\": torch.bfloat16},\n",
    "        device_map=\"auto\",\n",
    "        token=os.getenv('HF_TOKEN')\n",
    "    )\n",
    "\n",
    "    terminators = [\n",
    "        pipeline.tokenizer.eos_token_id,\n",
    "        pipeline.tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
    "    ]\n",
    "    \n",
    "    messages = [\n",
    "    {\"role\": \"system\", \"content\": sys_prompt + ' ' + memo_prompt},\n",
    "    {\"role\": \"user\", \"content\": problem},\n",
    "    ]\n",
    "\n",
    "    outputs = pipeline(\n",
    "    messages,\n",
    "    max_new_tokens=max_toks,\n",
    "    eos_token_id=terminators,\n",
    "    do_sample=True,\n",
    "    temperature=0.6,\n",
    "    top_p=0.9,\n",
    "    pad_token_id=pipeline.tokenizer.eos_token_id\n",
    "    )\n",
    "\n",
    "    return outputs[0]['generated_text'][-1]['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem_prompt = \"What is the dot product of these two vectors?\"\n",
    "cot_prompt = \"Show your work.\"\n",
    "memo_prompt = \"\"\"Answer with only a number. Do not do any calculations. For example:\n",
    "                 Problem: [2, 9, -3] ⋅ [-6, -2, -9]\n",
    "                 Solution: -3\n",
    "                 \"\"\"\n",
    "n=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def repeated_solve_problem_memo(model, problem, sys_prompt, memo_prompt, max_toks=10, return_retries=False):\n",
    "    soln = solve_problem_memo(model, problem, sys_prompt, memo_prompt, max_toks=max_toks)\n",
    "    i = 0\n",
    "    while sum([len([n for n in soln if n.isnumeric()]) > 3]):\n",
    "        if i >= 50: # tap out\n",
    "            return soln if not return_retries else (soln, i)\n",
    "        i += 1\n",
    "        print('retrying', i, soln)\n",
    "        soln = solve_problem_memo(model, problem, sys_prompt, memo_prompt, max_toks=max_toks)\n",
    "    return soln if not return_retries else (soln, i)\n",
    "\n",
    "def test_memo_prompt(model, memo_prompt):\n",
    "    dot_problems = make_dot_product_problem_set(3, 10, n)\n",
    "    memo_solutions = []\n",
    "    memo_correct = 0\n",
    "    for i, row in tqdm(list(dot_problems.iterrows())[:n]):\n",
    "        memo_solutions.append(repeated_solve_problem_memo(row['problem'], problem_prompt, memo_prompt=memo_prompt, max_toks=20))\n",
    "        memo_correct += str(row['correct_solution']) in memo_solutions[-1]\n",
    "    print(sum([len([n for n in x if n.isnumeric()]) <= 2 for x in memo_solutions]))\n",
    "    print('\\n'.join(memo_solutions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_memo_prompt(model, memo_prompt, n):\n",
    "    dot_problems = make_dot_product_problem_set(3, 10, n)\n",
    "    memo_solutions = []\n",
    "    memo_correct = 0\n",
    "    max_retries = 0\n",
    "    for i, row in tqdm(list(dot_problems.iterrows())[:n]):\n",
    "        sol, retries = repeated_solve_problem_memo(model, row['problem'], problem_prompt, memo_prompt=memo_prompt, max_toks=20, return_retries=True)\n",
    "        memo_solutions.append(sol)\n",
    "        memo_correct += str(row['correct_solution']) in memo_solutions[-1]\n",
    "        max_retries = max(max_retries, retries)\n",
    "    print(f\"Max retries: {max_retries}\")\n",
    "    print(f\"Correctness: {memo_correct}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Llama 8b reproduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Failed to import transformers.pipelines because of the following error (look up to see its traceback):\nNo module named 'optimum'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/import_utils.py:1603\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1602\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1603\u001b[0m     \u001b[39mreturn\u001b[39;00m importlib\u001b[39m.\u001b[39;49mimport_module(\u001b[39m\"\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m\"\u001b[39;49m \u001b[39m+\u001b[39;49m module_name, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__name__\u001b[39;49m)\n\u001b[1;32m   1604\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/usr/lib/python3.10/importlib/__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m         level \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m--> 126\u001b[0m \u001b[39mreturn\u001b[39;00m _bootstrap\u001b[39m.\u001b[39;49m_gcd_import(name[level:], package, level)\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1050\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1027\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1006\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:688\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:883\u001b[0m, in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:241\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/__init__.py:77\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mtext_generation\u001b[39;00m \u001b[39mimport\u001b[39;00m TextGenerationPipeline\n\u001b[0;32m---> 77\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mtext_to_audio\u001b[39;00m \u001b[39mimport\u001b[39;00m TextToAudioPipeline\n\u001b[1;32m     78\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mtoken_classification\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     79\u001b[0m     AggregationStrategy,\n\u001b[1;32m     80\u001b[0m     NerPipeline,\n\u001b[1;32m     81\u001b[0m     TokenClassificationArgumentHandler,\n\u001b[1;32m     82\u001b[0m     TokenClassificationPipeline,\n\u001b[1;32m     83\u001b[0m )\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/text_to_audio.py:22\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mauto\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodeling_auto\u001b[39;00m \u001b[39mimport\u001b[39;00m MODEL_FOR_TEXT_TO_SPECTROGRAM_MAPPING\n\u001b[0;32m---> 22\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mspeecht5\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodeling_speecht5\u001b[39;00m \u001b[39mimport\u001b[39;00m SpeechT5HifiGan\n\u001b[1;32m     24\u001b[0m DEFAULT_VOCODER_ID \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mmicrosoft/speecht5_hifigan\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/speecht5/modeling_speecht5.py:36\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodeling_outputs\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     30\u001b[0m     BaseModelOutput,\n\u001b[1;32m     31\u001b[0m     BaseModelOutputWithPastAndCrossAttentions,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     34\u001b[0m     Seq2SeqSpectrogramOutput,\n\u001b[1;32m     35\u001b[0m )\n\u001b[0;32m---> 36\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodeling_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m PreTrainedModel\n\u001b[1;32m     37\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m add_start_docstrings, add_start_docstrings_to_model_forward, logging, replace_return_docstrings\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:58\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mpytorch_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m (  \u001b[39m# noqa: F401\u001b[39;00m\n\u001b[1;32m     49\u001b[0m     Conv1D,\n\u001b[1;32m     50\u001b[0m     apply_chunking_to_forward,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     56\u001b[0m     prune_linear_layer,\n\u001b[1;32m     57\u001b[0m )\n\u001b[0;32m---> 58\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mquantizers\u001b[39;00m \u001b[39mimport\u001b[39;00m AutoHfQuantizer, HfQuantizer\n\u001b[1;32m     59\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mquantizers\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mquantizers_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m get_module_from_name\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/quantizers/__init__.py:14\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Copyright 2024 The HuggingFace Inc. team. All rights reserved.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[39m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[39m# limitations under the License.\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mauto\u001b[39;00m \u001b[39mimport\u001b[39;00m AutoHfQuantizer, AutoQuantizationConfig\n\u001b[1;32m     15\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mbase\u001b[39;00m \u001b[39mimport\u001b[39;00m HfQuantizer\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/quantizers/auto.py:36\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mquantizer_fbgemm_fp8\u001b[39;00m \u001b[39mimport\u001b[39;00m FbgemmFp8HfQuantizer\n\u001b[0;32m---> 36\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mquantizer_gptq\u001b[39;00m \u001b[39mimport\u001b[39;00m GptqHfQuantizer\n\u001b[1;32m     37\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mquantizer_hqq\u001b[39;00m \u001b[39mimport\u001b[39;00m HqqHfQuantizer\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/quantizers/quantizer_gptq.py:20\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mbase\u001b[39;00m \u001b[39mimport\u001b[39;00m HfQuantizer\n\u001b[0;32m---> 20\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39moptimum\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[39mif\u001b[39;00m TYPE_CHECKING:\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'optimum'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/root/stego-snowball/calibrated_data.ipynb Cell 10\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bdatacrunch/root/stego-snowball/calibrated_data.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m model_id \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mmeta-llama/Meta-Llama-3-8B-Instruct\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bdatacrunch/root/stego-snowball/calibrated_data.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m test_memo_prompt(model_id, memo_prompt\u001b[39m=\u001b[39;49mmemo_prompt, n\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m)\n",
      "\u001b[1;32m/root/stego-snowball/calibrated_data.ipynb Cell 10\u001b[0m line \u001b[0;36m7\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bdatacrunch/root/stego-snowball/calibrated_data.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m max_retries \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bdatacrunch/root/stego-snowball/calibrated_data.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mfor\u001b[39;00m i, row \u001b[39min\u001b[39;00m tqdm(\u001b[39mlist\u001b[39m(dot_problems\u001b[39m.\u001b[39miterrows())[:n]):\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bdatacrunch/root/stego-snowball/calibrated_data.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m     sol, retries \u001b[39m=\u001b[39m repeated_solve_problem_memo(model, row[\u001b[39m'\u001b[39;49m\u001b[39mproblem\u001b[39;49m\u001b[39m'\u001b[39;49m], problem_prompt, memo_prompt\u001b[39m=\u001b[39;49mmemo_prompt, max_toks\u001b[39m=\u001b[39;49m\u001b[39m20\u001b[39;49m, return_retries\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bdatacrunch/root/stego-snowball/calibrated_data.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m     memo_solutions\u001b[39m.\u001b[39mappend(sol)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bdatacrunch/root/stego-snowball/calibrated_data.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m     memo_correct \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(row[\u001b[39m'\u001b[39m\u001b[39mcorrect_solution\u001b[39m\u001b[39m'\u001b[39m]) \u001b[39min\u001b[39;00m memo_solutions[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n",
      "\u001b[1;32m/root/stego-snowball/calibrated_data.ipynb Cell 10\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bdatacrunch/root/stego-snowball/calibrated_data.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrepeated_solve_problem_memo\u001b[39m(model, problem, sys_prompt, memo_prompt, max_toks\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, return_retries\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bdatacrunch/root/stego-snowball/calibrated_data.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m     soln \u001b[39m=\u001b[39m solve_problem_memo(model, problem, sys_prompt, memo_prompt, max_toks\u001b[39m=\u001b[39;49mmax_toks)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bdatacrunch/root/stego-snowball/calibrated_data.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m     i \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bdatacrunch/root/stego-snowball/calibrated_data.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39msum\u001b[39m([\u001b[39mlen\u001b[39m([n \u001b[39mfor\u001b[39;00m n \u001b[39min\u001b[39;00m soln \u001b[39mif\u001b[39;00m n\u001b[39m.\u001b[39misnumeric()]) \u001b[39m>\u001b[39m \u001b[39m3\u001b[39m]):\n",
      "\u001b[1;32m/root/stego-snowball/calibrated_data.ipynb Cell 10\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bdatacrunch/root/stego-snowball/calibrated_data.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=31'>32</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msolve_problem_memo\u001b[39m(model_id, problem, sys_prompt, memo_prompt, max_toks\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m): \u001b[39m# setting max_toks to 1 because we're doing small digit numbers\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bdatacrunch/root/stego-snowball/calibrated_data.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=32'>33</a>\u001b[0m     pipeline \u001b[39m=\u001b[39m transformers\u001b[39m.\u001b[39;49mpipeline(\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bdatacrunch/root/stego-snowball/calibrated_data.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=33'>34</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mtext-generation\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bdatacrunch/root/stego-snowball/calibrated_data.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=34'>35</a>\u001b[0m         model\u001b[39m=\u001b[39mmodel_id,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bdatacrunch/root/stego-snowball/calibrated_data.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=35'>36</a>\u001b[0m         model_kwargs\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mtorch_dtype\u001b[39m\u001b[39m\"\u001b[39m: torch\u001b[39m.\u001b[39mbfloat16},\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bdatacrunch/root/stego-snowball/calibrated_data.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=36'>37</a>\u001b[0m         device_map\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mauto\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bdatacrunch/root/stego-snowball/calibrated_data.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=37'>38</a>\u001b[0m         token\u001b[39m=\u001b[39mos\u001b[39m.\u001b[39mgetenv(\u001b[39m'\u001b[39m\u001b[39mHF_TOKEN\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bdatacrunch/root/stego-snowball/calibrated_data.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=38'>39</a>\u001b[0m     )\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bdatacrunch/root/stego-snowball/calibrated_data.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=40'>41</a>\u001b[0m     terminators \u001b[39m=\u001b[39m [\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bdatacrunch/root/stego-snowball/calibrated_data.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=41'>42</a>\u001b[0m         pipeline\u001b[39m.\u001b[39mtokenizer\u001b[39m.\u001b[39meos_token_id,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bdatacrunch/root/stego-snowball/calibrated_data.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=42'>43</a>\u001b[0m         pipeline\u001b[39m.\u001b[39mtokenizer\u001b[39m.\u001b[39mconvert_tokens_to_ids(\u001b[39m\"\u001b[39m\u001b[39m<|eot_id|>\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bdatacrunch/root/stego-snowball/calibrated_data.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=43'>44</a>\u001b[0m     ]\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bdatacrunch/root/stego-snowball/calibrated_data.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=45'>46</a>\u001b[0m     messages \u001b[39m=\u001b[39m [\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bdatacrunch/root/stego-snowball/calibrated_data.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=46'>47</a>\u001b[0m     {\u001b[39m\"\u001b[39m\u001b[39mrole\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39msystem\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcontent\u001b[39m\u001b[39m\"\u001b[39m: sys_prompt \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m memo_prompt},\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bdatacrunch/root/stego-snowball/calibrated_data.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=47'>48</a>\u001b[0m     {\u001b[39m\"\u001b[39m\u001b[39mrole\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39muser\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcontent\u001b[39m\u001b[39m\"\u001b[39m: problem},\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bdatacrunch/root/stego-snowball/calibrated_data.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=48'>49</a>\u001b[0m     ]\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/import_utils.py:1593\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1591\u001b[0m     value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_module(name)\n\u001b[1;32m   1592\u001b[0m \u001b[39melif\u001b[39;00m name \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_class_to_module\u001b[39m.\u001b[39mkeys():\n\u001b[0;32m-> 1593\u001b[0m     module \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_module(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_class_to_module[name])\n\u001b[1;32m   1594\u001b[0m     value \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(module, name)\n\u001b[1;32m   1595\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/import_utils.py:1605\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1603\u001b[0m     \u001b[39mreturn\u001b[39;00m importlib\u001b[39m.\u001b[39mimport_module(\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m module_name, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)\n\u001b[1;32m   1604\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m-> 1605\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1606\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFailed to import \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{\u001b[39;00mmodule_name\u001b[39m}\u001b[39;00m\u001b[39m because of the following error (look up to see its\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1607\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m traceback):\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00me\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1608\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Failed to import transformers.pipelines because of the following error (look up to see its traceback):\nNo module named 'optimum'"
     ]
    }
   ],
   "source": [
    "model_id = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "test_memo_prompt(model_id, memo_prompt=memo_prompt, n=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
